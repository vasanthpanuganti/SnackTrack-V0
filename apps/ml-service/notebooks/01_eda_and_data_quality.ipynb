{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SnackTrack ML --- Exploratory Data Analysis\n",
    "\n",
    "This notebook performs a comprehensive EDA across **all** data sources available to the\n",
    "SnackTrack recommendation engine:\n",
    "\n",
    "| Source | What we look at |\n",
    "|--------|----------------|\n",
    "| **Kaggle datasets** (Parquet) | Recipe nutrition, ingredients, ratings, daily food logs |\n",
    "| **PostgreSQL database** | Live recipes, user interactions, meal logs, taste profiles, dietary preferences |\n",
    "\n",
    "### Goals\n",
    "\n",
    "1. Understand the **shape and quality** of every dataset\n",
    "2. Visualize **nutrition distributions** and compare across sources\n",
    "3. Explore **diet labels, allergens, and cuisine types**\n",
    "4. Analyze **user interaction patterns** (ratings, temporal trends)\n",
    "5. Examine **meal patterns** from daily food logs\n",
    "6. Produce a consolidated **data quality summary**\n",
    "\n",
    "> **Prerequisite**: Run `00_download_datasets.ipynb` first to download and convert datasets to Parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Allow imports from the parent directory\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from notebooks.utils.plot_helpers import setup_plot_style, SNACKTRACK_COLORS, PALETTE\n",
    "\n",
    "setup_plot_style()\n",
    "\n",
    "print(\"Environment ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load All Datasets\n",
    "\n",
    "We load from **two** sources:\n",
    "\n",
    "- **Database** -- via `utils.db_connect.get_connection()` and the various `load_*_from_db()` helpers.\n",
    "  Wrapped in `try/except` so the notebook still works when no database is available.\n",
    "- **Kaggle Parquet files** -- via `utils.data_loader.load_kaggle_dataset()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks.utils.data_loader import (\n",
    "    load_kaggle_dataset,\n",
    "    load_recipes_from_db,\n",
    "    load_interactions_from_db,\n",
    "    load_meal_logs_from_db,\n",
    "    load_user_profiles_from_db,\n",
    "    load_dietary_preferences_from_db,\n",
    ")\n",
    "from notebooks.utils.db_connect import get_connection\n",
    "\n",
    "# ---- Database data (optional) ----\n",
    "db_recipes = pd.DataFrame()\n",
    "db_interactions = pd.DataFrame()\n",
    "db_meal_logs = pd.DataFrame()\n",
    "db_user_profiles = pd.DataFrame()\n",
    "db_dietary_prefs = pd.DataFrame()\n",
    "db_available = False\n",
    "\n",
    "try:\n",
    "    conn = get_connection()\n",
    "    db_recipes = load_recipes_from_db(conn)\n",
    "    db_interactions = load_interactions_from_db(conn)\n",
    "    db_meal_logs = load_meal_logs_from_db(conn)\n",
    "    db_user_profiles = load_user_profiles_from_db(conn)\n",
    "    db_dietary_prefs = load_dietary_preferences_from_db(conn)\n",
    "    conn.close()\n",
    "    db_available = True\n",
    "    print(f\"Database connected. Loaded:\")\n",
    "    print(f\"  recipes:       {len(db_recipes):>7,} rows\")\n",
    "    print(f\"  interactions:  {len(db_interactions):>7,} rows\")\n",
    "    print(f\"  meal_logs:     {len(db_meal_logs):>7,} rows\")\n",
    "    print(f\"  user_profiles: {len(db_user_profiles):>7,} rows\")\n",
    "    print(f\"  dietary_prefs: {len(db_dietary_prefs):>7,} rows\")\n",
    "except Exception as e:\n",
    "    print(f\"Database not available ({type(e).__name__}: {e}).\")\n",
    "    print(\"Continuing with Kaggle data only.\")\n",
    "\n",
    "# ---- Kaggle datasets (from Parquet) ----\n",
    "kaggle_data: dict[str, pd.DataFrame] = {}\n",
    "\n",
    "KAGGLE_NAMES = [\n",
    "    \"diet_recommendations\",\n",
    "    \"daily_food_nutrition\",\n",
    "    \"medical_diet\",\n",
    "    \"epicurious\",\n",
    "    \"recipe_ingredients\",\n",
    "    \"global_food_nutrition\",\n",
    "    \"recipes_64k\",\n",
    "    \"food_recommendation\",\n",
    "]\n",
    "\n",
    "# Food.com has multiple files -- try common sub-file naming\n",
    "KAGGLE_MULTI = [\n",
    "    \"foodcom_reviews\",\n",
    "    \"foodcom_interactions\",\n",
    "]\n",
    "\n",
    "for name in KAGGLE_NAMES:\n",
    "    try:\n",
    "        kaggle_data[name] = load_kaggle_dataset(name)\n",
    "        print(f\"  {name:<30s} {kaggle_data[name].shape[0]:>9,} rows  {kaggle_data[name].shape[1]:>3} cols\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  {name:<30s} NOT FOUND (run notebook 00 first)\")\n",
    "\n",
    "# For multi-file datasets, try loading each sub-file\n",
    "from notebooks.utils.dataset_downloader import DATA_DIR\n",
    "\n",
    "for name in KAGGLE_MULTI:\n",
    "    # Try single file first\n",
    "    try:\n",
    "        kaggle_data[name] = load_kaggle_dataset(name)\n",
    "        print(f\"  {name:<30s} {kaggle_data[name].shape[0]:>9,} rows  {kaggle_data[name].shape[1]:>3} cols\")\n",
    "        continue\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    # Try sub-files: data/<name>__<stem>.parquet\n",
    "    sub_files = sorted(DATA_DIR.glob(f\"{name}__*.parquet\"))\n",
    "    for sf in sub_files:\n",
    "        sub_key = sf.stem  # e.g. foodcom_reviews__recipes\n",
    "        try:\n",
    "            kaggle_data[sub_key] = pd.read_parquet(sf)\n",
    "            print(f\"  {sub_key:<30s} {kaggle_data[sub_key].shape[0]:>9,} rows  {kaggle_data[sub_key].shape[1]:>3} cols\")\n",
    "        except Exception as e:\n",
    "            print(f\"  {sub_key:<30s} LOAD ERROR: {e}\")\n",
    "\n",
    "    if not sub_files:\n",
    "        print(f\"  {name:<30s} NOT FOUND\")\n",
    "\n",
    "print(f\"\\nTotal Kaggle datasets loaded: {len(kaggle_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Recipe Corpus Analysis\n",
    "\n",
    "We merge recipe data from multiple sources and examine the distribution of key\n",
    "nutritional fields: **calories, protein, carbs, fat, fiber, sugar, sodium**.\n",
    "\n",
    "This helps us understand:\n",
    "- Value ranges across datasets (do we need clipping/normalization?)\n",
    "- Whether certain datasets are biased toward high/low calorie foods\n",
    "- How well the Kaggle data matches our database recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect nutrition columns from every source that has them\n",
    "NUTRITION_COLS = [\"calories\", \"protein_g\", \"carbs_g\", \"fat_g\", \"fiber_g\", \"sugar_g\", \"sodium_mg\"]\n",
    "\n",
    "# Mapping of common column name variants to our canonical names\n",
    "COL_ALIASES = {\n",
    "    \"protein\": \"protein_g\",\n",
    "    \"protein_g\": \"protein_g\",\n",
    "    \"carbohydrates\": \"carbs_g\",\n",
    "    \"carbs\": \"carbs_g\",\n",
    "    \"carbs_g\": \"carbs_g\",\n",
    "    \"total_carbohydrate_g\": \"carbs_g\",\n",
    "    \"fat\": \"fat_g\",\n",
    "    \"fat_g\": \"fat_g\",\n",
    "    \"total_fat_g\": \"fat_g\",\n",
    "    \"fiber\": \"fiber_g\",\n",
    "    \"fiber_g\": \"fiber_g\",\n",
    "    \"dietary_fiber_g\": \"fiber_g\",\n",
    "    \"sugar\": \"sugar_g\",\n",
    "    \"sugar_g\": \"sugar_g\",\n",
    "    \"sugars_g\": \"sugar_g\",\n",
    "    \"sodium\": \"sodium_mg\",\n",
    "    \"sodium_mg\": \"sodium_mg\",\n",
    "    \"sodium_mg_\": \"sodium_mg\",\n",
    "    \"calories\": \"calories\",\n",
    "    \"energy_kcal\": \"calories\",\n",
    "}\n",
    "\n",
    "\n",
    "def extract_nutrition(df: pd.DataFrame, source: str) -> pd.DataFrame:\n",
    "    \"\"\"Extract and rename nutrition columns from a dataset.\"\"\"\n",
    "    renamed = {}\n",
    "    for col in df.columns:\n",
    "        canonical = COL_ALIASES.get(col.lower())\n",
    "        if canonical and canonical not in renamed:\n",
    "            renamed[canonical] = df[col]\n",
    "    if not renamed:\n",
    "        return pd.DataFrame()\n",
    "    out = pd.DataFrame(renamed)\n",
    "    out[\"source\"] = source\n",
    "    return out\n",
    "\n",
    "\n",
    "nutrition_frames = []\n",
    "\n",
    "# Database recipes\n",
    "if not db_recipes.empty:\n",
    "    nutrition_frames.append(extract_nutrition(db_recipes, \"db_recipes\"))\n",
    "\n",
    "# Kaggle datasets that may contain nutrition\n",
    "for name, df in kaggle_data.items():\n",
    "    nf = extract_nutrition(df, name)\n",
    "    if not nf.empty:\n",
    "        nutrition_frames.append(nf)\n",
    "\n",
    "if nutrition_frames:\n",
    "    all_nutrition = pd.concat(nutrition_frames, ignore_index=True)\n",
    "    print(f\"Combined nutrition data: {len(all_nutrition):,} rows from {all_nutrition['source'].nunique()} sources\")\n",
    "    print(f\"Sources: {sorted(all_nutrition['source'].unique())}\")\n",
    "    print()\n",
    "    display(all_nutrition.describe().round(1))\n",
    "else:\n",
    "    all_nutrition = pd.DataFrame()\n",
    "    print(\"No nutrition data found in any loaded dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all_nutrition.empty:\n",
    "    available_cols = [c for c in NUTRITION_COLS if c in all_nutrition.columns]\n",
    "\n",
    "    # --- Histograms of each nutrition column ---\n",
    "    n_cols = min(4, len(available_cols))\n",
    "    n_rows = (len(available_cols) + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4 * n_rows))\n",
    "    axes = np.atleast_2d(axes).flatten()\n",
    "\n",
    "    for i, col in enumerate(available_cols):\n",
    "        ax = axes[i]\n",
    "        data = all_nutrition[col].dropna()\n",
    "        # Clip extreme outliers for readability\n",
    "        upper = data.quantile(0.99)\n",
    "        data_clipped = data[data <= upper]\n",
    "        ax.hist(data_clipped, bins=60, color=PALETTE[i % len(PALETTE)], alpha=0.7, edgecolor=\"white\")\n",
    "        ax.set_title(col, fontsize=13)\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.axvline(data.median(), color=\"red\", linestyle=\"--\", linewidth=1, label=f\"median={data.median():.0f}\")\n",
    "        ax.legend(fontsize=9)\n",
    "\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    fig.suptitle(\"Nutrition Distributions (clipped at 99th percentile)\", fontsize=15, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- Box plots by source ---\n",
    "    sources = sorted(all_nutrition[\"source\"].unique())\n",
    "    if len(sources) > 1:\n",
    "        fig, axes = plt.subplots(1, min(4, len(available_cols)), figsize=(18, 5))\n",
    "        axes = np.atleast_1d(axes)\n",
    "\n",
    "        for i, col in enumerate(available_cols[:4]):\n",
    "            ax = axes[i]\n",
    "            plot_data = all_nutrition[[col, \"source\"]].dropna()\n",
    "            upper = plot_data[col].quantile(0.95)\n",
    "            plot_data = plot_data[plot_data[col] <= upper]\n",
    "            sns.boxplot(data=plot_data, x=\"source\", y=col, ax=ax, palette=PALETTE)\n",
    "            ax.set_title(col, fontsize=12)\n",
    "            ax.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "        fig.suptitle(\"Nutrition Comparison Across Datasets (clipped at 95th pctl)\", fontsize=14, y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Skipping nutrition plots -- no data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Diet Label & Allergen Distributions\n",
    "\n",
    "The `global_food_nutrition` dataset contains allergen flags (`contains_gluten`,\n",
    "`contains_dairy`, etc.) and diet/cuisine labels. We visualize these to understand\n",
    "the label balance for knowledge-based filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfn = kaggle_data.get(\"global_food_nutrition\", pd.DataFrame())\n",
    "\n",
    "if not gfn.empty:\n",
    "    # --- Allergen flags ---\n",
    "    allergen_cols = [c for c in gfn.columns if c.startswith(\"contains_\")]\n",
    "    if allergen_cols:\n",
    "        allergen_counts = gfn[allergen_cols].sum().sort_values(ascending=True)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, max(4, len(allergen_cols) * 0.5)))\n",
    "        allergen_counts.plot.barh(ax=ax, color=SNACKTRACK_COLORS[\"accent\"], edgecolor=\"white\")\n",
    "        ax.set_xlabel(\"Number of foods\")\n",
    "        ax.set_title(\"Allergen Flag Frequency (global_food_nutrition)\", fontsize=13)\n",
    "        for i, v in enumerate(allergen_counts.values):\n",
    "            ax.text(v + 50, i, f\"{v:,}\", va=\"center\", fontsize=9)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No allergen flag columns found.\")\n",
    "\n",
    "    # --- Diet labels ---\n",
    "    diet_col = None\n",
    "    for candidate in [\"diet_labels\", \"diet_label\", \"diet_type\", \"dietary_label\"]:\n",
    "        if candidate in gfn.columns:\n",
    "            diet_col = candidate\n",
    "            break\n",
    "\n",
    "    if diet_col:\n",
    "        diet_counts = gfn[diet_col].value_counts().head(20)\n",
    "        fig, ax = plt.subplots(figsize=(12, 5))\n",
    "        diet_counts.plot.bar(ax=ax, color=SNACKTRACK_COLORS[\"primary\"], edgecolor=\"white\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.set_title(f\"Top 20 Diet Labels ({diet_col})\", fontsize=13)\n",
    "        ax.tick_params(axis=\"x\", rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # --- Cuisine types ---\n",
    "    cuisine_col = None\n",
    "    for candidate in [\"cuisine_types\", \"cuisine_type\", \"cuisine\"]:\n",
    "        if candidate in gfn.columns:\n",
    "            cuisine_col = candidate\n",
    "            break\n",
    "\n",
    "    if cuisine_col:\n",
    "        cuisine_counts = gfn[cuisine_col].value_counts().head(20)\n",
    "        fig, ax = plt.subplots(figsize=(12, 5))\n",
    "        cuisine_counts.plot.bar(ax=ax, color=SNACKTRACK_COLORS[\"secondary\"], edgecolor=\"white\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.set_title(f\"Top 20 Cuisine Types ({cuisine_col})\", fontsize=13)\n",
    "        ax.tick_params(axis=\"x\", rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"global_food_nutrition not loaded -- skipping diet label & allergen analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. User Interaction Analysis\n",
    "\n",
    "We examine user--recipe interactions from two potential sources:\n",
    "\n",
    "1. **Food.com interactions** (Kaggle) -- ratings, review counts, temporal activity\n",
    "2. **Database `user_interactions`** -- SnackTrack-native events (`cook`, `log`, `rate`, `view`, `swap_accept`, `swap_reject`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Food.com interactions (Kaggle) ---\n",
    "# Try several possible keys for the Food.com interaction data\n",
    "foodcom_int = None\n",
    "for key in [\"foodcom_interactions\", \"foodcom_interactions__interactions_train\",\n",
    "            \"foodcom_interactions__train\", \"foodcom_interactions__RAW_interactions\"]:\n",
    "    if key in kaggle_data:\n",
    "        foodcom_int = kaggle_data[key]\n",
    "        print(f\"Using Food.com interactions from: {key}  ({len(foodcom_int):,} rows)\")\n",
    "        break\n",
    "\n",
    "if foodcom_int is not None:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    # (a) Rating distribution\n",
    "    rating_col = None\n",
    "    for c in [\"rating\", \"score\", \"review_score\"]:\n",
    "        if c in foodcom_int.columns:\n",
    "            rating_col = c\n",
    "            break\n",
    "    if rating_col:\n",
    "        axes[0].hist(foodcom_int[rating_col].dropna(), bins=20, color=SNACKTRACK_COLORS[\"primary\"],\n",
    "                     edgecolor=\"white\", alpha=0.8)\n",
    "        axes[0].set_title(\"Rating Distribution\", fontsize=13)\n",
    "        axes[0].set_xlabel(\"Rating\")\n",
    "        axes[0].set_ylabel(\"Count\")\n",
    "    else:\n",
    "        axes[0].text(0.5, 0.5, \"No rating column found\", ha=\"center\", va=\"center\", transform=axes[0].transAxes)\n",
    "\n",
    "    # (b) Interactions per user (log scale)\n",
    "    user_col = None\n",
    "    for c in [\"user_id\", \"authorid\", \"author_id\"]:\n",
    "        if c in foodcom_int.columns:\n",
    "            user_col = c\n",
    "            break\n",
    "    if user_col:\n",
    "        per_user = foodcom_int[user_col].value_counts()\n",
    "        axes[1].hist(per_user.values, bins=100, color=SNACKTRACK_COLORS[\"accent\"],\n",
    "                     edgecolor=\"white\", alpha=0.8, log=True)\n",
    "        axes[1].set_title(\"Interactions per User (log scale)\", fontsize=13)\n",
    "        axes[1].set_xlabel(\"Number of interactions\")\n",
    "        axes[1].set_ylabel(\"Number of users\")\n",
    "    else:\n",
    "        axes[1].text(0.5, 0.5, \"No user_id column found\", ha=\"center\", va=\"center\", transform=axes[1].transAxes)\n",
    "\n",
    "    # (c) Temporal pattern\n",
    "    date_col = None\n",
    "    for c in [\"date\", \"submitted\", \"created_at\", \"review_date\"]:\n",
    "        if c in foodcom_int.columns:\n",
    "            date_col = c\n",
    "            break\n",
    "    if date_col:\n",
    "        dates = pd.to_datetime(foodcom_int[date_col], errors=\"coerce\").dropna()\n",
    "        axes[2].hist(dates.dt.year, bins=30, color=SNACKTRACK_COLORS[\"secondary\"],\n",
    "                     edgecolor=\"white\", alpha=0.8)\n",
    "        axes[2].set_title(\"Interactions Over Time\", fontsize=13)\n",
    "        axes[2].set_xlabel(\"Year\")\n",
    "        axes[2].set_ylabel(\"Count\")\n",
    "    else:\n",
    "        axes[2].text(0.5, 0.5, \"No date column found\", ha=\"center\", va=\"center\", transform=axes[2].transAxes)\n",
    "\n",
    "    fig.suptitle(\"Food.com Interaction Analysis\", fontsize=15, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Food.com interaction data not available.\")\n",
    "\n",
    "# --- Database interactions ---\n",
    "if not db_interactions.empty:\n",
    "    print(f\"\\nDatabase interactions: {len(db_interactions):,} rows\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # (a) Interaction type distribution\n",
    "    type_counts = db_interactions[\"interaction_type\"].value_counts()\n",
    "    type_counts.plot.bar(ax=axes[0], color=PALETTE[:len(type_counts)], edgecolor=\"white\")\n",
    "    axes[0].set_title(\"Interaction Types (DB)\", fontsize=13)\n",
    "    axes[0].set_ylabel(\"Count\")\n",
    "    axes[0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    # (b) Interactions per user\n",
    "    per_user_db = db_interactions[\"user_id\"].value_counts()\n",
    "    axes[1].hist(per_user_db.values, bins=50, color=SNACKTRACK_COLORS[\"accent\"],\n",
    "                 edgecolor=\"white\", alpha=0.8)\n",
    "    axes[1].set_title(\"Interactions per User (DB)\", fontsize=13)\n",
    "    axes[1].set_xlabel(\"Number of interactions\")\n",
    "    axes[1].set_ylabel(\"Number of users\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No database interactions available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Meal Patterns\n",
    "\n",
    "The `daily_food_nutrition` dataset contains individual food log entries with\n",
    "**meal types** (`breakfast`, `lunch`, `dinner`, `snack`) and food categories.\n",
    "We analyze these patterns to inform our RNN meal-sequence model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = kaggle_data.get(\"daily_food_nutrition\", pd.DataFrame())\n",
    "\n",
    "if not dfn.empty:\n",
    "    print(f\"daily_food_nutrition: {len(dfn):,} rows, {dfn.shape[1]} columns\")\n",
    "    print(f\"Columns: {list(dfn.columns)}\\n\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "    # (a) Meal type distribution\n",
    "    meal_col = None\n",
    "    for c in [\"meal_type\", \"meal\", \"mealtype\"]:\n",
    "        if c in dfn.columns:\n",
    "            meal_col = c\n",
    "            break\n",
    "\n",
    "    if meal_col:\n",
    "        meal_counts = dfn[meal_col].value_counts()\n",
    "        colors = PALETTE[:len(meal_counts)]\n",
    "        axes[0].pie(meal_counts.values, labels=meal_counts.index, autopct=\"%1.1f%%\",\n",
    "                    colors=colors, startangle=90)\n",
    "        axes[0].set_title(f\"Meal Type Distribution ({meal_col})\", fontsize=13)\n",
    "    else:\n",
    "        axes[0].text(0.5, 0.5, \"No meal_type column found\", ha=\"center\", va=\"center\",\n",
    "                     transform=axes[0].transAxes)\n",
    "\n",
    "    # (b) Food category breakdown\n",
    "    cat_col = None\n",
    "    for c in [\"food_category\", \"category\", \"food_group\", \"food_type\"]:\n",
    "        if c in dfn.columns:\n",
    "            cat_col = c\n",
    "            break\n",
    "\n",
    "    if cat_col:\n",
    "        cat_counts = dfn[cat_col].value_counts().head(15)\n",
    "        cat_counts.plot.barh(ax=axes[1], color=SNACKTRACK_COLORS[\"primary\"], edgecolor=\"white\")\n",
    "        axes[1].set_xlabel(\"Count\")\n",
    "        axes[1].set_title(f\"Top 15 Food Categories ({cat_col})\", fontsize=13)\n",
    "        axes[1].invert_yaxis()\n",
    "    else:\n",
    "        axes[1].text(0.5, 0.5, \"No food category column found\", ha=\"center\", va=\"center\",\n",
    "                     transform=axes[1].transAxes)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"daily_food_nutrition not loaded -- skipping meal pattern analysis.\")\n",
    "\n",
    "# Also check database meal logs\n",
    "if not db_meal_logs.empty:\n",
    "    print(f\"\\nDB meal_logs: {len(db_meal_logs):,} rows\")\n",
    "    if \"meal_type\" in db_meal_logs.columns:\n",
    "        print(db_meal_logs[\"meal_type\"].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Quality Summary\n",
    "\n",
    "A consolidated view of every dataset's size, completeness, and key features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_rows = []\n",
    "\n",
    "# Database tables\n",
    "db_tables = {\n",
    "    \"db: recipes\": db_recipes,\n",
    "    \"db: interactions\": db_interactions,\n",
    "    \"db: meal_logs\": db_meal_logs,\n",
    "    \"db: user_profiles\": db_user_profiles,\n",
    "    \"db: dietary_prefs\": db_dietary_prefs,\n",
    "}\n",
    "for name, df in db_tables.items():\n",
    "    if df.empty:\n",
    "        continue\n",
    "    null_pct = (df.isnull().sum().sum() / (df.shape[0] * df.shape[1]) * 100) if df.size > 0 else 0\n",
    "    key_features = \", \".join(list(df.columns)[:6])\n",
    "    summary_rows.append({\n",
    "        \"Dataset\": name,\n",
    "        \"Rows\": f\"{df.shape[0]:,}\",\n",
    "        \"Columns\": df.shape[1],\n",
    "        \"Null %\": f\"{null_pct:.1f}%\",\n",
    "        \"Key Features\": key_features + (\"...\" if df.shape[1] > 6 else \"\"),\n",
    "    })\n",
    "\n",
    "# Kaggle datasets\n",
    "for name, df in sorted(kaggle_data.items()):\n",
    "    null_pct = (df.isnull().sum().sum() / (df.shape[0] * df.shape[1]) * 100) if df.size > 0 else 0\n",
    "    key_features = \", \".join(list(df.columns)[:6])\n",
    "    summary_rows.append({\n",
    "        \"Dataset\": name,\n",
    "        \"Rows\": f\"{df.shape[0]:,}\",\n",
    "        \"Columns\": df.shape[1],\n",
    "        \"Null %\": f\"{null_pct:.1f}%\",\n",
    "        \"Key Features\": key_features + (\"...\" if df.shape[1] > 6 else \"\"),\n",
    "    })\n",
    "\n",
    "if summary_rows:\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "    # Style the table\n",
    "    styled = (\n",
    "        summary_df.style\n",
    "        .set_properties(**{\"text-align\": \"left\"})\n",
    "        .set_table_styles([\n",
    "            {\"selector\": \"th\", \"props\": [(\"background-color\", SNACKTRACK_COLORS[\"primary\"]),\n",
    "                                          (\"color\", \"white\"), (\"font-weight\", \"bold\")]},\n",
    "            {\"selector\": \"td\", \"props\": [(\"padding\", \"6px 12px\")]},\n",
    "        ])\n",
    "        .hide(axis=\"index\")\n",
    "    )\n",
    "    display(styled)\n",
    "else:\n",
    "    print(\"No datasets were loaded. Run notebook 00 first.\")\n",
    "\n",
    "print(\"\\nEDA complete. Proceed to notebook 02 for content-based filtering analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}